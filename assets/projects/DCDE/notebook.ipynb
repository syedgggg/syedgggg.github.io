{"cells":[{"source":"# Data Engineer Certification - Practical Exam - Supplement Experiments\n\n1001-Experiments makes personalized supplements tailored to individual health needs.\n\n1001-Experiments aims to enhance personal health by using data from wearable devices and health apps.\n\nThis data, combined with user feedback and habits, is used to analyze and refine the effectiveness of the supplements provided to the user through multiple small experiments.\n\nThe data engineering team at 1001-Experiments plays a crucial role in ensuring the collected health and activity data from thousands of users is accurately organized and integrated with the data from supplement usage. \n\nThis integration helps 1001-Experiments provide more targeted health and wellness recommendations and improve supplement formulations.","metadata":{},"id":"7c0d155c-27e6-4a08-a509-b1d1a9bde901","cell_type":"markdown"},{"source":"\n## Task\n\n1001-Experiments currently has the following four datasets with four months of data:\n - \"user_health_data.csv\" which logs daily health metrics, habits and data from wearable devices,\n - \"supplement_usage.csv\" which records details on supplement intake per user,\n - \"experiments.csv\" which contains metadata on experiments, and\n - \"user_profiles.csv\" which contains demographic and contact information of the users.\n\nEach dataset contains unique identifiers for users and/or their supplement regimen.\n\nThe developers and data scientsits currently manage code that cross-references all of these data sources separately, which is cumbersome and error-prone.\n\nYour manager has asked you to write a Python function that cleans and merges these datasets into a single dataset.\n\nThe final dataset should provide a comprehensive view of each user's health metrics, supplement usage, and demographic information.\n\n- To test your code, your manager will run only the code `merge_all_data('user_health_data.csv', 'supplement_usage.csv', 'experiments.csv', 'user_profiles.csv')`\n- Your `merge_all_data` function must return a DataFrame, with columns as described below.\n- All columns must accurately match the descriptions provided below, including names.\n","metadata":{},"id":"f70773d5-4944-40cd-b323-6a4a6952b602","cell_type":"markdown"},{"source":"## Data\n\nThe provided data is structured as follows:\n\n![database schema](schema.png)\n\nThe function you write should return data as described below.\n\nThere should be a unique row for each daily entry combining health metrics and supplement usage.\n\nWhere missing values are permitted, they should be in the default Python format unless stated otherwise.\n\n| Column Name        | Description |\n|--------------------|-------------|\n| user_id            | Unique identifier for each user. </br>There should not be any missing values. |\n| date               | The date the health data was recorded or the supplement was taken, in date format. </br>There should not be any missing values. |\n| email              | Contact email of the user. </br>There should not be any missing values. |\n| user_age_group  | The age group of the user, one of: 'Under 18', '18-25', '26-35', '36-45', '46-55', '56-65', 'Over 65' or 'Unknown' where the age is missing.|\n| experiment_name    | Name of the experiment associated with the supplement usage. </br>Missing values for users that have user health data only is permitted. |\n| supplement_name    | The name of the supplement taken on that day. Multiple entries are permitted. </br>Days without supplement intake should be encoded as 'No intake'. |\n| dosage_grams       | The dosage of the supplement taken in grams. Where the dosage is recorded in mg it should be converted by division by 1000.</br>Missing values for days without supplement intake are permitted. |\n| is_placebo         | Indicator if the supplement was a placebo (true/false). </br>Missing values for days without supplement intake are permitted. |\n| average_heart_rate | Average heart rate as recorded by the wearable device. </br>Missing values are permitted. |\n| average_glucose    | Average glucose levels as recorded on the wearable device. </br>Missing values are permitted. |\n| sleep_hours        | Total sleep in hours for the night preceding the current dayâ€™s log. </br>Missing values are permitted. |\n| activity_level     | Activity level score between 0-100. </br>Missing values are permitted. |","metadata":{},"id":"1c04a3f0-7613-4430-8eac-e76d855d80af","cell_type":"markdown"},{"source":"# test function call: merge_all_data('user_health_data.csv', 'supplement_usage.csv', 'experiments.csv', 'user_profiles.csv')\ndef merge_all_data(csv1, csv2, csv3, csv4):\n    import pandas as pd\n    import numpy as np\n    \n    # read in csv files as pandas dataframe\n    df_user_health = pd.read_csv(csv1) # logs daily health metrics, habits and data from wearable devices\n    df_supplement_usage = pd.read_csv(csv2) # records details on supplement intake per user\n    df_experiments = pd.read_csv(csv3) # contains metadata on experiments\n    df_user_profiles = pd.read_csv(csv4) # contains demographic and contact information of the users\n    \n    # merge df_health and df_usage\n    # df_combined = pd.concat([df_user_health, df_supplement_usage], ignore_index=True, sort=False) # stack both dataframes vertically\n    df_combined = pd.merge(df_supplement_usage, df_user_health, on=[\"user_id\", 'date'], how='outer')\n    df_combined = pd.merge(df_combined, df_user_profiles, on=\"user_id\", how=\"outer\") # pull rows from both dataframes\n    df_combined = pd.merge(df_combined, df_experiments, on=\"experiment_id\", how=\"outer\") # pull rows from both dataframes\n\n\t# DATA CLEANING\n\n    # date: cast from object to datetime object\n    df_combined['date'] = pd.to_datetime(df_combined['date'])\n\n    # user_age_group: create categories and add category for missing values\n    df_combined['user_age_group'] = pd.cut(df_combined['age'], bins=[-np.inf,17,25,35,45,55,65,np.inf], labels=['Under 18', '18-25', '26-35', '36-45', '46-55', '56-65', 'Over 65'])\n    df_combined['user_age_group'] = df_combined['user_age_group'].cat.add_categories('Unknown').fillna('Unknown')\n\n    # experiment_name: select needed columns and change one column's name\n    df_combined = df_combined.rename(columns={'name':'experiment_name'})\n\n    # supplement_name: No intake on null\n    df_combined['supplement_name'].fillna(\"No intake\", inplace=True)\n\n    # dosage_grams: scale dosage by 1/1000\n    df_combined['dosage_grams'] = df_combined['dosage']/1000\n\n    # sleep_hours: remove string and convert to float (personal)\n    df_combined['sleep_hours'] = df_combined['sleep_hours'].str.replace(r'[hH]$', '', regex=True).astype(float)\n\n    # final column selection\n    df_combined = df_combined[['user_id', 'date', 'email', 'user_age_group', 'experiment_name', 'supplement_name', 'dosage_grams', 'is_placebo', 'average_heart_rate', 'average_glucose', 'sleep_hours', 'activity_level']]\n    return df_combined","metadata":{"executionCancelledAt":null,"executionTime":15,"lastExecutedAt":1739497198045,"lastExecutedByKernel":"6322be77-a4ca-41e2-924a-b1a29db021d0","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# test function call: merge_all_data('user_health_data.csv', 'supplement_usage.csv', 'experiments.csv', 'user_profiles.csv')\ndef merge_all_data(csv1, csv2, csv3, csv4):\n    import pandas as pd\n    import numpy as np\n    \n    # read in csv files as pandas dataframe\n    df_user_health = pd.read_csv(csv1) # logs daily health metrics, habits and data from wearable devices\n    df_supplement_usage = pd.read_csv(csv2) # records details on supplement intake per user\n    df_experiments = pd.read_csv(csv3) # contains metadata on experiments\n    df_user_profiles = pd.read_csv(csv4) # contains demographic and contact information of the users\n    \n    # merge df_health and df_usage\n    # df_combined = pd.concat([df_user_health, df_supplement_usage], ignore_index=True, sort=False) # stack both dataframes vertically\n    df_combined = pd.merge(df_supplement_usage, df_user_health, on=[\"user_id\", 'date'], how='outer')\n    df_combined = pd.merge(df_combined, df_user_profiles, on=\"user_id\", how=\"outer\") # pull rows from both dataframes\n    df_combined = pd.merge(df_combined, df_experiments, on=\"experiment_id\", how=\"outer\") # pull rows from both dataframes\n\n\t# DATA CLEANING\n\n    # date: cast from object to datetime object\n    df_combined['date'] = pd.to_datetime(df_combined['date'])\n\n    # user_age_group: create categories and add category for missing values\n    df_combined['user_age_group'] = pd.cut(df_combined['age'], bins=[-np.inf,17,25,35,45,55,65,np.inf], labels=['Under 18', '18-25', '26-35', '36-45', '46-55', '56-65', 'Over 65'])\n    df_combined['user_age_group'] = df_combined['user_age_group'].cat.add_categories('Unknown').fillna('Unknown')\n\n    # experiment_name: select needed columns and change one column's name\n    df_combined = df_combined.rename(columns={'name':'experiment_name'})\n\n    # supplement_name: No intake on null\n    df_combined['supplement_name'].fillna(\"No intake\", inplace=True)\n\n    # dosage_grams: scale dosage by 1/1000\n    df_combined['dosage_grams'] = df_combined['dosage']/1000\n\n    # sleep_hours: remove string and convert to float (personal)\n    df_combined['sleep_hours'] = df_combined['sleep_hours'].str.replace(r'[hH]$', '', regex=True).astype(float)\n\n    # final column selection\n    df_combined = df_combined[['user_id', 'date', 'email', 'user_age_group', 'experiment_name', 'supplement_name', 'dosage_grams', 'is_placebo', 'average_heart_rate', 'average_glucose', 'sleep_hours', 'activity_level']]\n    return df_combined"},"cell_type":"code","id":"9c168bfb-b550-4ebb-a224-f3050360868d","outputs":[],"execution_count":94}],"metadata":{"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}