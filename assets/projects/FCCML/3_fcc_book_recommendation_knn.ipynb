{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0BOA1TxUud4"
      },
      "source": [
        "# Book Recommendation Engine using KNN\n",
        "\n",
        "Create a book recommendation algorithm using **K-Nearest Neighbors** (algorithm measures the distance to determine the â€œclosenessâ€ of instances).\n",
        "\n",
        "You will use the [Book-Crossings dataset](https://www2.informatik.uni-freiburg.de/~cziegler/BX/). This dataset contains 1.1 million ratings (scale of 1-10) of 270,000 books by 90,000 users.\n",
        "\n",
        "function `get_recommends()` takes book title (from the dataset) as an argument and returns list of 5 similar books with distances\n",
        "\n",
        "code:\n",
        "\n",
        "`get_recommends(\"The Queen of the Damned (Vampire Chronicles (Paperback))\")`\n",
        "\n",
        "returns:\n",
        "\n",
        "```python\n",
        "[\n",
        "  'The Queen of the Damned (Vampire Chronicles (Paperback))',\n",
        "  [\n",
        "    ['Catch 22', 0.793983519077301],\n",
        "    ['The Witching Hour (Lives of the Mayfair Witches)', 0.7448656558990479],\n",
        "    ['Interview with the Vampire', 0.7345068454742432],\n",
        "    ['The Tale of the Body Thief (Vampire Chronicles (Paperback))', 0.5376338362693787],\n",
        "    ['The Vampire Lestat (Vampire Chronicles, Book II)', 0.5178412199020386]\n",
        "  ]\n",
        "]\n",
        "```\n",
        "\n",
        "To ensure statistical significance, remove from the dataset users with less than 200 ratings and books with less than 100 ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Y1onB6kUvo4Z"
      },
      "outputs": [],
      "source": [
        "# import libraries (you may add additional imports but you may not have to)\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iAQGqqO_vo4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13d24c1c-f913-4b2b-d859-3b7c83b6f96a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-05 00:58:27--  https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
            "Resolving cdn.freecodecamp.org (cdn.freecodecamp.org)... 104.26.2.33, 104.26.3.33, 172.67.70.149, ...\n",
            "Connecting to cdn.freecodecamp.org (cdn.freecodecamp.org)|104.26.2.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26085508 (25M) [application/zip]\n",
            "Saving to: â€˜book-crossings.zipâ€™\n",
            "\n",
            "book-crossings.zip  100%[===================>]  24.88M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-10-05 00:58:27 (193 MB/s) - â€˜book-crossings.zipâ€™ saved [26085508/26085508]\n",
            "\n",
            "Archive:  book-crossings.zip\n",
            "  inflating: BX-Book-Ratings.csv     \n",
            "  inflating: BX-Books.csv            \n",
            "  inflating: BX-Users.csv            \n"
          ]
        }
      ],
      "source": [
        "# get data files\n",
        "!wget https://cdn.freecodecamp.org/project-data/books/book-crossings.zip\n",
        "\n",
        "!unzip book-crossings.zip\n",
        "\n",
        "books_filename = 'BX-Books.csv'\n",
        "ratings_filename = 'BX-Book-Ratings.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NClILWOiEd6Q"
      },
      "outputs": [],
      "source": [
        "# import csv data into dataframes\n",
        "df_books = pd.read_csv(\n",
        "    books_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['isbn', 'title', 'author'],\n",
        "    usecols=['isbn', 'title', 'author'],\n",
        "    dtype={'isbn': 'str', 'title': 'str', 'author': 'str'})\n",
        "\n",
        "df_ratings = pd.read_csv(\n",
        "    ratings_filename,\n",
        "    encoding = \"ISO-8859-1\",\n",
        "    sep=\";\",\n",
        "    header=0,\n",
        "    names=['user', 'isbn', 'rating'],\n",
        "    usecols=['user', 'isbn', 'rating'],\n",
        "    dtype={'user': 'int32', 'isbn': 'str', 'rating': 'float32'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMkTR3U3UueC",
        "outputId": "15b4eb26-2b6a-4ec4-be91-ffddb710263d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-6a056d1e9386>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_merged_filtered.dropna(inplace=True, how='all')\n",
            "<ipython-input-4-6a056d1e9386>:17: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_merged_filtered.drop_duplicates(subset=['title', 'user'], keep='first', inplace=True)\n",
            "<ipython-input-4-6a056d1e9386>:20: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_merged_filtered.drop_duplicates(subset=['title', 'user', 'author'], keep='first', inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# merge both dataframes into one dataframe\n",
        "df_merged = pd.merge(df_books, df_ratings, on='isbn', how=\"right\")\n",
        "\n",
        "# ensure statistical significance, remove users with less than 200 ratings\n",
        "user_above_200 = df_merged['user'].value_counts(ascending=True).to_frame().query(\"user >= 200\")\n",
        "\n",
        "# ensure statistical significance, remove books with less than 100 ratings\n",
        "isbn_above_100 = df_merged['isbn'].value_counts(ascending=True).to_frame().query(\"isbn >= 100\")\n",
        "\n",
        "# ensure rows where only statistical significance conditions are met\n",
        "df_merged_filtered = df_merged[(df_merged['user'].isin(user_above_200.index)) & (df_merged['isbn'].isin(isbn_above_100.index))]\n",
        "\n",
        "# drop rows where all values are missing\n",
        "df_merged_filtered.dropna(inplace=True, how='all')\n",
        "\n",
        "# drop duplicates based on same title and user\n",
        "df_merged_filtered.drop_duplicates(subset=['title', 'user'], keep='first', inplace=True)\n",
        "\n",
        "# drop duplicates based on same title, user and author\n",
        "df_merged_filtered.drop_duplicates(subset=['title', 'user', 'author'], keep='first', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pwPc_iQAUueD"
      },
      "outputs": [],
      "source": [
        "# generate pivot table\n",
        "df_pivot = df_merged_filtered.pivot_table(index = 'title', columns = 'user', values = 'rating').fillna(0)\n",
        "\n",
        "# generate sparse matrix\n",
        "csr_matrix = csr_matrix(df_pivot)\n",
        "\n",
        "# generate nearest neighbors model\n",
        "nn = NearestNeighbors(metric='cosine').fit(csr_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "f5ZUd-L1SQz7"
      },
      "outputs": [],
      "source": [
        "# function to return recommended books - this will be tested\n",
        "def get_recommends(book = \"\"):\n",
        "  # get distance and indices given book\n",
        "  distance, indices = nn.kneighbors([df_pivot.loc[book]], n_neighbors=6, return_distance=True)\n",
        "\n",
        "  # get book list, flatten array into 1d, drop first element, reverse entire array and pull out index only\n",
        "  book_list = df_pivot.iloc[indices.flatten()[1:][::-1]].index.tolist()\n",
        "\n",
        "  # turn 2d array into 1d array, drop first element, reverse entire array\n",
        "  distance_filtered_reversed = distance.flatten()[1:][::-1]\n",
        "\n",
        "  # generate recommendation matrix\n",
        "  recommend_matrix = [[book_list[i], distance_filtered_reversed[i]] for i in range(len(book_list))]\n",
        "\n",
        "  # generate recommended books matrix\n",
        "  recommended_books = [\n",
        "    df_pivot.iloc[indices.flatten()[0]].name,\n",
        "    recommend_matrix\n",
        "    ]\n",
        "\n",
        "  return recommended_books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jd2SLCh8oxMh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76c2174-3f65-482c-d8eb-b9d848e8abea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Where the Heart Is (Oprah's Book Club (Paperback))\", [[\"I'll Be Seeing You\", 0.8016211], ['The Weight of Water', 0.77085835], ['The Surgeon', 0.7699411], ['I Know This Much Is True', 0.7677075], ['The Lovely Bones: A Novel', 0.7234864]]]\n",
            "You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\n"
          ]
        }
      ],
      "source": [
        "books = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "print(books)\n",
        "\n",
        "def test_book_recommendation():\n",
        "  test_pass = True\n",
        "  recommends = get_recommends(\"Where the Heart Is (Oprah's Book Club (Paperback))\")\n",
        "  if recommends[0] != \"Where the Heart Is (Oprah's Book Club (Paperback))\":\n",
        "    test_pass = False\n",
        "  recommended_books = [\"I'll Be Seeing You\", 'The Weight of Water', 'The Surgeon', 'I Know This Much Is True']\n",
        "  recommended_books_dist = [0.8, 0.77, 0.77, 0.77]\n",
        "  for i in range(2):\n",
        "    if recommends[1][i][0] not in recommended_books:\n",
        "      test_pass = False\n",
        "    if abs(recommends[1][i][1] - recommended_books_dist[i]) >= 0.05:\n",
        "      test_pass = False\n",
        "  if test_pass:\n",
        "    print(\"You passed the challenge! ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "  else:\n",
        "    print(\"You haven't passed yet. Keep trying!\")\n",
        "\n",
        "test_book_recommendation()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}